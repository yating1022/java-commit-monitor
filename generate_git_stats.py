import os
import shutil
import tempfile
import json
from datetime import datetime, timedelta, timezone
import pandas as pd
import git
import pytz # éœ€è¦å®‰è£… pytz åº“ç”¨äºæ—¶åŒºè½¬æ¢

# ================= é…ç½® =================
REPO_URL = "https://github.com/mdlldz/java.git"
OUTPUT_DIR = "public"
JSON_FILE = os.path.join(OUTPUT_DIR, "data.json")
TEMPLATE_FILE = "index.html"
SHANGHAI_TZ = 'Asia/Shanghai' # å®šä¹‰ä¸œå…«åŒºæ—¶åŒº
# =======================================

def fetch_commit_data(repo_url):
    """å…‹éš†ä»“åº“å¹¶è·å–æäº¤æ•°æ®ã€‚"""
    temp_dir = tempfile.mkdtemp()
    print(f"ğŸš€ æ­£åœ¨å…‹éš†ä»“åº“ {repo_url}...")
    try:
        repo = git.Repo.clone_from(repo_url, temp_dir) 
        commits_list = []
        
        print("ğŸ“Š æ­£åœ¨åˆ†ææäº¤æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
        for commit in repo.iter_commits(max_count=2000):
            try:
                stats = commit.stats.total
                lines_changed = stats.get('lines', 0)
            except Exception:
                lines_changed = 0

            # æ³¨æ„ï¼šè¿™é‡Œç›´æ¥ä½¿ç”¨ datetime.fromtimestamp(commit.committed_date) 
            # è·å–çš„æ˜¯ naive datetime å¯¹è±¡ï¼Œåç»­åœ¨ process_to_json ä¸­è¿›è¡Œæ—¶åŒºæ ‡è®°å’Œè½¬æ¢ã€‚
            commits_list.append({
                'hash': commit.hexsha[:7],
                'date': datetime.fromtimestamp(commit.committed_date), 
                'message': commit.message.strip(),
                'timestamp': commit.committed_date,
                'lines': lines_changed
            })
        return pd.DataFrame(commits_list)
    except Exception as e:
        print(f"âŒ å…‹éš†æˆ–åˆ†æä»“åº“æ—¶å‡ºé”™: {e}")
        return None
    finally:
        try:
            if 'repo' in locals() and repo:
                repo.close()
            shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def calculate_streak(dates):
    """è®¡ç®—è¿ç»­æäº¤å¤©æ•°ã€‚"""
    if not dates:
        return 0
    
    # ç¡®ä¿ä»Šå¤©çš„æ—¶é—´æ˜¯ä¸œå…«åŒºçš„æ—¶é—´ï¼Œç”¨äºè¿å‡»è®¡ç®—
    try:
        tz = pytz.timezone(SHANGHAI_TZ)
    except pytz.UnknownTimeZoneError:
        print("âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ° 'Asia/Shanghai' æ—¶åŒºï¼Œä½¿ç”¨ UTCã€‚")
        tz = timezone.utc
        
    now_shanghai = datetime.now(tz)
    today = now_shanghai.date()
    
    # å°†æ—¥æœŸåˆ—è¡¨è½¬æ¢ä¸º date å¯¹è±¡å¹¶æ’åº
    unique_dates = sorted(list(set(d.date() if isinstance(d, datetime) else d for d in dates)), reverse=True)
    
    if not unique_dates:
        return 0
        
    latest_commit_date = unique_dates[0]
    current_streak = 0
    
    # æ£€æŸ¥æœ€æ–°æäº¤æ˜¯å¦åœ¨ä»Šå¤©æˆ–æ˜¨å¤©
    if latest_commit_date < today - timedelta(days=1):
        return 0
        
    # ä»ä»Šå¤©/æœ€æ–°ä¸€å¤©å¼€å§‹å¾€å‰æ¨
    # ç¡®å®šæ£€æŸ¥çš„èµ·å§‹æ—¥æœŸï¼šå¦‚æœæ˜¯ä»Šå¤©ï¼Œä»ä»Šå¤©å¼€å§‹ï¼›å¦åˆ™ä»æ˜¨å¤©å¼€å§‹
    start_date = today
    
    # å¾ªç¯æ£€æŸ¥è¿å‡»
    for i in range(len(unique_dates)):
        expected_date = start_date - timedelta(days=i)
        
        if expected_date in unique_dates:
            current_streak += 1
            # å¦‚æœä»Šå¤©æœ‰æäº¤ï¼Œåˆ™è®¡ç®—ä»ä»Šå¤©å¼€å§‹
            if expected_date == today and current_streak == 1:
                # å·²ç»æ£€æŸ¥è¿‡ä»Šå¤©ï¼Œç°åœ¨ç»§ç»­æ£€æŸ¥æ˜¨å¤©
                start_date = today 
            continue
        elif expected_date == latest_commit_date:
             # å¦‚æœæœ€æ–°æäº¤æ—¥æœŸæ˜¯æ˜¨å¤©ï¼Œè€Œä»Šå¤©æ²¡æœ‰æäº¤ï¼Œè¿å‡»ä»æ˜¨å¤©å¼€å§‹
            current_streak += 1
            continue
        else:
            # é‡åˆ°é—´æ–­
            break

    # ç®€åŒ–è¿å‡»è®¡ç®—ï¼šä»æœ€æ–°çš„æ—¥æœŸå¼€å§‹æ£€æŸ¥è¿ç»­æ€§
    current_streak = 0
    dates_set = set(unique_dates)
    
    # æ£€æŸ¥ä»Šå¤©å’Œæ˜¨å¤©
    check_date = today
    if check_date in dates_set:
        current_streak += 1
    check_date = today - timedelta(days=1)
    if check_date in dates_set:
        current_streak += 1
    
    # ä»å‰å¤©å¼€å§‹ç»§ç»­æ£€æŸ¥
    for i in range(2, 365): # é™åˆ¶æ£€æŸ¥ä¸€å¹´å†…çš„è¿å‡»
        expected_date = today - timedelta(days=i)
        if expected_date in dates_set:
            if current_streak > 0 and (expected_date + timedelta(days=1)) in dates_set:
                current_streak += 1
            elif current_streak == 0 and expected_date == latest_commit_date:
                # ç¡®ä¿å½“æœ€æ–°æäº¤æ˜¯æ˜¨å¤©æˆ–æ›´æ—©æ—¶ï¼Œè¿å‡»ä¹Ÿèƒ½è¢«æ­£ç¡®è®¡ç®—
                if latest_commit_date >= today - timedelta(days=1):
                     current_streak = 1 if latest_commit_date == today else 0 
                     # è¿™é‡Œé€»è¾‘å¤æ‚ä¸”å®¹æ˜“å‡ºé”™ï¼Œç®€åŒ–ä¸ºï¼š
                     # å¦‚æœæœ€æ–°æäº¤æ—©äºæ˜¨å¤©ï¼Œåˆ™è¿å‡»å½’é›¶
                     if latest_commit_date < today - timedelta(days=1):
                         return 0
                     
                     # ä»æœ€æ–°çš„æ—¥æœŸå¼€å§‹å¾€å‰æ¨
                     start_date_check = latest_commit_date
                     streak = 1
                     while (start_date_check - timedelta(days=1)) in dates_set:
                         start_date_check -= timedelta(days=1)
                         streak += 1
                     
                     return streak if latest_commit_date >= today - timedelta(days=1) else 0

            else:
                break
        else:
            break
            
    # é‡æ–°æ‰§è¡Œç²¾ç¡®çš„è¿å‡»è®¡ç®—ï¼ˆç®€åŒ–ä¸”ç¨³å¥çš„é€»è¾‘ï¼‰ï¼š
    current_streak = 0
    if not unique_dates:
        return 0

    dates_set = set(unique_dates)
    
    # ä»ä»Šå¤©å¼€å§‹æ£€æŸ¥è¿å‡»
    start_date_check = today
    if start_date_check in dates_set:
        current_streak += 1
    
    # æ— è®ºä»Šå¤©æœ‰æ²¡æœ‰ï¼Œéƒ½æ£€æŸ¥æ˜¨å¤©çš„è¿å‡»
    start_date_check = today - timedelta(days=1)
    if start_date_check in dates_set and (start_date_check + timedelta(days=1)) in dates_set:
        current_streak += 1

    # ä»å‰å¤©å¼€å§‹å¾€å‰è¿½æº¯è¿å‡»
    for i in range(2, 365 * 3): # è¿½æº¯æœ€å¤šä¸‰å¹´
        expected_date = today - timedelta(days=i)
        
        # åªè¦å‰ä¸€å¤©æœ‰æäº¤ï¼Œè¿å‡»å°±å¢åŠ 
        if expected_date in dates_set and (expected_date + timedelta(days=1)) in dates_set:
            current_streak += 1
        else:
            break
            
    # å¦‚æœä»Šå¤©çš„æäº¤ä¸å­˜åœ¨ï¼Œè¿å‡»ä»æ˜¨å¤©å¼€å§‹è®¡ç®—ï¼Œä¸”å¿…é¡»æ˜¯è¿ç»­çš„
    if today not in dates_set:
         # æ‰¾åˆ°æœ€æ–°çš„æäº¤æ—¥æœŸ
         if latest_commit_date < today - timedelta(days=1):
             return 0 # æ–­å¼€
         
         # ä»æœ€æ–°çš„æ—¥æœŸå¼€å§‹è®¡ç®—è¿ç»­æ€§
         current_streak = 0
         start_date_check = latest_commit_date
         while start_date_check in dates_set:
             current_streak += 1
             start_date_check -= timedelta(days=1)
         
         return current_streak

    return current_streak


def process_to_json(df):
    """
    æ•°æ®å¤„ç†ä¸ç»“æ„åŒ–ï¼Œç›´æ¥åœ¨ç°æœ‰åˆ—ä¸Šè¿›è¡Œä¸œå…«åŒºæ—¶åŒºè½¬æ¢ã€‚
    é¿å…åˆ›å»ºæ–°çš„è¾…åŠ©åˆ—ï¼Œä»…ä½¿ç”¨ dateã€day_strã€hourã€weekday è¿›è¡Œè®¡ç®—ã€‚
    """
    # 1. æ—¶åŒºè½¬æ¢
    # 'date' åˆ—æ˜¯ naive datetimeï¼Œå‡è®¾å®ƒæ˜¯ UTC æ—¶é—´
    df['date'] = pd.to_datetime(df['date']).dt.tz_localize('UTC')
    
    # å°†å…¶è½¬æ¢ä¸ºä¸œå…«åŒºæ—¶é—´ (Asia/Shanghai) å¹¶è¦†ç›–åŸå§‹åˆ—
    df['date'] = df['date'].dt.tz_convert(SHANGHAI_TZ)
    
    # 2. æå–ç»Ÿè®¡æ‰€éœ€çš„åˆ—ï¼ˆä¸åˆ›å»ºæ°¸ä¹…æ–°åˆ—ï¼‰
    df['day_str'] = df['date'].dt.date
    df['hour'] = df['date'].dt.hour
    df['weekday'] = df['date'].dt.weekday # [0=å‘¨ä¸€, 6=å‘¨æ—¥]
    
    # 3. è®¡ç®—å…ƒæ•°æ®
    total_commits = len(df)
    total_lines = int(df['lines'].sum())
    # last_update ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´æ ¼å¼åŒ–
    last_update = df['date'].max().strftime("%Y-%m-%d %H:%M") 
    
    unique_days = df['day_str'].unique().tolist()
    current_streak = calculate_streak(unique_days)
    
    # 4. è¶‹åŠ¿å›¾æ•°æ® (Trend)
    daily_counts = df.groupby('day_str').size().reset_index(name='count')
    daily_counts = daily_counts.sort_values('day_str')
    
    # 5. çƒ­åŠ›å›¾æ•°æ® (Heatmap)
    heatmap_data = []
    grouped = df.groupby(['weekday', 'hour']).size().reset_index(name='count') 
    for _, row in grouped.iterrows():
        # çƒ­åŠ›å›¾æ•°æ®æ ¼å¼: [å°æ—¶ (0-23), æ˜ŸæœŸå‡  (0-6), æäº¤æ•°]
        heatmap_data.append([int(row['hour']), int(row['weekday']), int(row['count'])])

    # 6. æœ€è¿‘æäº¤ (Recent)
    recent_commits = df.head(10)[['hash', 'message', 'date', 'lines']].copy()
    # ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´è¿›è¡Œæ ¼å¼åŒ–ï¼ˆåŒ…å«æ—¶åŒºä¿¡æ¯ï¼‰
    recent_commits['date'] = recent_commits['date'].dt.strftime("%Y-%m-%d %H:%M:%S %Z")
    recent_records = recent_commits.to_dict(orient='records')
    
    # 7. ç§»é™¤è¾…åŠ©åˆ—ï¼Œåªä¿ç•™åŸå§‹åˆ— (hash, date, message, timestamp, lines)
    # df.drop(columns=['day_str', 'hour', 'weekday'], inplace=True) 
    # ^ å®é™…ä¸Šï¼Œç”±äº process_to_json çš„ df æ˜¯ä¸€ä¸ªå‰¯æœ¬æˆ–åœ¨å‡½æ•°å†…ä½œç”¨åŸŸï¼Œä¸éœ€è¦æ¸…ç†ã€‚
    
    data = {
        "meta": {
            "repo": REPO_URL.split('/')[-1].replace('.git', ''),
            "updated": last_update,
            "total": total_commits,
            "streak": current_streak,
            "total_lines": total_lines
        },
        "trend": {
            "dates": daily_counts['day_str'].astype(str).tolist(),
            "values": daily_counts['count'].tolist()
        },
        "heatmap": heatmap_data,
        "recent": recent_records
    }
    return data

def main():
    """ä¸»å‡½æ•°ã€‚"""
    # 1. å‡†å¤‡è¾“å‡ºç›®å½•
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    # 2. å¤åˆ¶é™æ€èµ„æº (å¢åŠ é˜²é”™é€»è¾‘)
    resources = [
        (TEMPLATE_FILE, "index.html"),
        ("public/style.css", "style.css"),
        ("public/script.js", "script.js")
    ]
    
    for src, dst_name in resources:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•åœ¨æ ¹ç›®å½•æ‰¾
        if not os.path.exists(src) and os.path.exists(os.path.basename(src)):
            src = os.path.basename(src)
            
        if os.path.exists(src):
            dst_path = os.path.join(OUTPUT_DIR, dst_name)
            
            # é¿å…å¤åˆ¶åˆ°è‡ªèº«
            if os.path.abspath(src) == os.path.abspath(dst_path):
                print(f"â„¹ï¸ è·³è¿‡å¤åˆ¶ (åŸåœ°æ–‡ä»¶): {src}")
                continue
                
            shutil.copy(src, dst_path)
            print(f"âœ… å·²å¤åˆ¶èµ„æº: {src} -> {dst_name}")
        else:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°èµ„æºæ–‡ä»¶ {src}")

    # 3. è·å–æ•°æ®å¹¶ç”Ÿæˆ JSON
    df = fetch_commit_data(REPO_URL)
    if df is not None and not df.empty:
        json_data = process_to_json(df)
        with open(JSON_FILE, 'w', encoding='utf-8') as f:
            # ä½¿ç”¨ indent=4 æ–¹ä¾¿é˜…è¯»ï¼Œå®é™…éƒ¨ç½²æ—¶å¯å»æ‰
            json.dump(json_data, f, ensure_ascii=False, indent=4) 
        print(f"ğŸ‰ æ•°æ®ç”ŸæˆæˆåŠŸ: {JSON_FILE}")
    else:
        print("âŒ æœªèƒ½è·å–æ•°æ®æˆ–æ•°æ®ä¸ºç©º")

if __name__ == "__main__":
    main()
