import os
import shutil
import tempfile
import json
from datetime import datetime, timedelta, timezone
import pandas as pd
import git
import pytz # ç¡®ä¿å·²å®‰è£…: pip install pytz

# ================= é…ç½® =================
REPO_URL = "https://github.com/mdlldz/java.git"
OUTPUT_DIR = "public"
JSON_FILE = os.path.join(OUTPUT_DIR, "data.json")
TEMPLATE_FILE = "index.html"
SHANGHAI_TZ = 'Asia/Shanghai' # å®šä¹‰ä¸œå…«åŒºæ—¶åŒº
# =======================================

def fetch_commit_data(repo_url):
    """å…‹éš†ä»“åº“å¹¶è·å–æäº¤æ•°æ®ã€‚"""
    temp_dir = tempfile.mkdtemp()
    print(f"ğŸš€ æ­£åœ¨å…‹éš†ä»“åº“ {repo_url}...")
    try:
        repo = git.Repo.clone_from(repo_url, temp_dir) 
        commits_list = []
        
        print("ğŸ“Š æ­£åœ¨åˆ†ææäº¤æ•°æ® (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
        for commit in repo.iter_commits(max_count=2000):
            try:
                stats = commit.stats.total
                lines_changed = stats.get('lines', 0)
            except Exception:
                lines_changed = 0

            # ä¿æŒ 'date' åˆ—ä¸º naive datetime å¯¹è±¡ï¼Œåç»­å†è¿›è¡Œæ—¶åŒºæ ‡è®°å’Œè½¬æ¢ã€‚
            commits_list.append({
                'hash': commit.hexsha[:7],
                'date': datetime.fromtimestamp(commit.committed_date), 
                'message': commit.message.strip(),
                'timestamp': commit.committed_date,
                'lines': lines_changed
            })
        return pd.DataFrame(commits_list)
    except Exception as e:
        print(f"âŒ å…‹éš†æˆ–åˆ†æä»“åº“æ—¶å‡ºé”™: {e}")
        return None
    finally:
        try:
            if 'repo' in locals() and repo:
                repo.close()
            shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def calculate_streak(dates):
    """
    è®¡ç®—è¿ç»­æäº¤å¤©æ•°ï¼ˆåŸºäºä¸œå…«åŒºæ—¶é—´ï¼‰ã€‚
    æ­¤ç‰ˆæœ¬é€»è¾‘æ›´ç®€æ´å’Œå¥å£®ã€‚
    """
    if not dates:
        return 0
    
    # 1. ç¡®å®šä»Šå¤©çš„æ—¥æœŸï¼ˆä¸œå…«åŒºï¼‰
    try:
        tz = pytz.timezone(SHANGHAI_TZ)
    except pytz.UnknownTimeZoneError:
        tz = timezone.utc
        
    now_shanghai = datetime.now(tz)
    today = now_shanghai.date()
    
    # 2. è·å–å”¯ä¸€çš„æäº¤æ—¥æœŸé›†åˆ
    dates_set = set(d.date() if isinstance(d, datetime) else d for d in dates)
    
    if not dates_set:
        return 0
        
    # 3. æ£€æŸ¥è¿å‡»æ˜¯å¦ä¸­æ–­
    # æ‰¾åˆ°æœ€æ–°çš„æäº¤æ—¥æœŸ
    latest_commit_date = max(dates_set) 
    
    # å¦‚æœæœ€æ–°æäº¤æ—¥æœŸæ—©äºâ€œæ˜¨å¤©â€ï¼Œåˆ™è¿å‡»ä¸º 0
    if latest_commit_date < today - timedelta(days=1):
        return 0
        
    current_streak = 0
    
    # 4. ä»ä»Šå¤©å¼€å§‹å€’æ¨æ£€æŸ¥è¿ç»­æ€§
    check_date = today
    
    # ä»ä»Šå¤©æˆ–æ˜¨å¤©å¼€å§‹è®¡ç®—
    # å¦‚æœä»Šå¤©æœ‰æäº¤ï¼Œä»ä»Šå¤©å¼€å§‹
    if check_date in dates_set:
        current_streak += 1
        check_date -= timedelta(days=1)
    # å¦‚æœä»Šå¤©æ²¡æœ‰æäº¤ï¼Œä½†æ˜¨å¤©æœ‰æäº¤ï¼Œè¿å‡»ä»æ˜¨å¤©å¼€å§‹ï¼ˆè¿å‡»é•¿åº¦ä¸º 1ï¼‰
    elif check_date - timedelta(days=1) in dates_set:
        current_streak += 1
        check_date -= timedelta(days=2) # ä»å‰å¤©å¼€å§‹ç»§ç»­æ£€æŸ¥
    else:
        return 0 # ä»Šå¤©å’Œæ˜¨å¤©éƒ½æ²¡æœ‰ï¼Œè¿å‡»ä¸­æ–­

    # 5. æŒç»­å¾€å‰æ£€æŸ¥
    while check_date in dates_set:
        current_streak += 1
        check_date -= timedelta(days=1)
        
    return current_streak

def process_to_json(df):
    """æ•°æ®å¤„ç†ä¸ç»“æ„åŒ–ï¼Œç›´æ¥åœ¨ç°æœ‰åˆ—ä¸Šè¿›è¡Œä¸œå…«åŒºæ—¶åŒºè½¬æ¢ã€‚"""
    
    # 1. æ—¶åŒºè½¬æ¢
    # 'date' åˆ—æ˜¯ naive datetimeï¼Œé¦–å…ˆå‡è®¾å®ƒæ˜¯ UTC æ—¶é—´è¿›è¡Œæœ¬åœ°åŒ–
    df['date'] = pd.to_datetime(df['date']).dt.tz_localize('UTC', ambiguous='NaT', nonexistent='shift_forward')
    
    # å°†å…¶è½¬æ¢ä¸ºä¸œå…«åŒºæ—¶é—´ (Asia/Shanghai) å¹¶è¦†ç›–åŸå§‹åˆ—
    df['date'] = df['date'].dt.tz_convert(SHANGHAI_TZ)
    
    # 2. æå–ç»Ÿè®¡æ‰€éœ€çš„åˆ—ï¼ˆä¸´æ—¶ä½¿ç”¨ï¼Œä¸åˆ›å»ºæŒä¹…æ–°åˆ—ï¼‰
    df['day_str'] = df['date'].dt.date
    df['hour'] = df['date'].dt.hour
    df['weekday'] = df['date'].dt.weekday # [0=å‘¨ä¸€, 6=å‘¨æ—¥]
    
    # 3. è®¡ç®—å…ƒæ•°æ®
    total_commits = len(df)
    total_lines = int(df['lines'].sum())
    # last_update ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´æ ¼å¼åŒ–ï¼Œæ˜¾ç¤ºæœ€æ–°çš„æäº¤æ—¶é—´
    last_update = df['date'].max().strftime("%Y-%m-%d %H:%M") 
    
    unique_days = df['day_str'].unique().tolist()
    current_streak = calculate_streak(unique_days)
    
    # 4. è¶‹åŠ¿å›¾æ•°æ® (Trend)
    daily_counts = df.groupby('day_str').size().reset_index(name='count')
    daily_counts = daily_counts.sort_values('day_str')
    
    # 5. çƒ­åŠ›å›¾æ•°æ® (Heatmap)
    heatmap_data = []
    grouped = df.groupby(['weekday', 'hour']).size().reset_index(name='count') 
    for _, row in grouped.iterrows():
        heatmap_data.append([int(row['hour']), int(row['weekday']), int(row['count'])])

    # 6. æœ€è¿‘æäº¤ (Recent)
    # ç¡®ä¿ 'date' å·²ç»è¢«è½¬æ¢ä¸ºä¸œå…«åŒºæ—¶é—´
    recent_commits = df.head(10)[['hash', 'message', 'date', 'lines']].copy()
    # ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´è¿›è¡Œæ ¼å¼åŒ–
    recent_commits['date'] = recent_commits['date'].dt.strftime("%Y-%m-%d %H:%M:%S %Z")
    recent_records = recent_commits.to_dict(orient='records')
    
    data = {
        "meta": {
            "repo": REPO_URL.split('/')[-1].replace('.git', ''),
            "updated": last_update,
            "total": total_commits,
            "streak": current_streak,
            "total_lines": total_lines
        },
        "trend": {
            "dates": daily_counts['day_str'].astype(str).tolist(),
            "values": daily_counts['count'].tolist()
        },
        "heatmap": heatmap_data,
        "recent": recent_records
    }
    return data

def main():
    """ä¸»å‡½æ•°ã€‚"""
    # 1. å‡†å¤‡è¾“å‡ºç›®å½•
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    # 2. å¤åˆ¶é™æ€èµ„æº (å¢åŠ é˜²é”™é€»è¾‘)
    resources = [
        (TEMPLATE_FILE, "index.html"),
        ("public/style.css", "style.css"),
        ("public/script.js", "script.js")
    ]
    
    for src, dst_name in resources:
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•åœ¨æ ¹ç›®å½•æ‰¾
        if not os.path.exists(src) and os.path.exists(os.path.basename(src)):
            src = os.path.basename(src)
            
        if os.path.exists(src):
            dst_path = os.path.join(OUTPUT_DIR, dst_name)
            
            # é¿å…å¤åˆ¶åˆ°è‡ªèº«
            if os.path.abspath(src) == os.path.abspath(dst_path):
                print(f"â„¹ï¸ è·³è¿‡å¤åˆ¶ (åŸåœ°æ–‡ä»¶): {src}")
                continue
                
            shutil.copy(src, dst_path)
            print(f"âœ… å·²å¤åˆ¶èµ„æº: {src} -> {dst_name}")
        else:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°èµ„æºæ–‡ä»¶ {src}")

    # 3. è·å–æ•°æ®å¹¶ç”Ÿæˆ JSON
    df = fetch_commit_data(REPO_URL)
    if df is not None and not df.empty:
        json_data = process_to_json(df)
        with open(JSON_FILE, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=4) 
        print(f"ğŸ‰ æ•°æ®ç”ŸæˆæˆåŠŸ: {JSON_FILE}")
    else:
        print("âŒ æœªèƒ½è·å–æ•°æ®æˆ–æ•°æ®ä¸ºç©º")

if __name__ == "__main__":
    main()
