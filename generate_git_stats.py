import os
import shutil
import tempfile
import json
from datetime import datetime, timedelta
import pandas as pd
import git

# ================= é…ç½® =================
REPO_URL = "https://github.com/mdlldz/java.git"
OUTPUT_DIR = "public"
JSON_FILE = os.path.join(OUTPUT_DIR, "data.json")
TEMPLATE_FILE = "index.html"
# =======================================

def fetch_commit_data(repo_url):
    temp_dir = tempfile.mkdtemp()
    print(f"ğŸš€ æ­£åœ¨å…‹éš†ä»“åº“ {repo_url}...")
    try:
        repo = git.Repo.clone_from(repo_url, temp_dir)
        commits_list = []
        # åªè¦æœ€è¿‘çš„ 5000 æ¡ï¼Œé˜²æ­¢æ•°æ®é‡è¿‡å¤§å¡é¡¿
        for commit in repo.iter_commits(max_count=5000):
            commits_list.append({
                'hash': commit.hexsha[:7], # çŸ­ hash
                'date': datetime.fromtimestamp(commit.committed_date),
                'message': commit.message.strip(),
                'timestamp': commit.committed_date
            })
        return pd.DataFrame(commits_list)
    finally:
        try:
            repo.close()
            shutil.rmtree(temp_dir)
        except Exception:
            pass

def calculate_streak(dates):
    """è®¡ç®—å½“å‰è¿ç»­æäº¤å¤©æ•°"""
    if not dates:
        return 0
    dates = sorted(list(set(dates)), reverse=True) # ä»å¤§åˆ°å°æ’
    current_streak = 0
    today = datetime.now().date()
    
    # å¦‚æœæœ€æ–°çš„æäº¤ä¸æ˜¯ä»Šå¤©æˆ–æ˜¨å¤©ï¼Œè¯´æ˜æ–­äº†
    if dates[0] < today - timedelta(days=1):
        return 0
        
    for i in range(len(dates)):
        expected_date = dates[0] - timedelta(days=i)
        if dates[i] == expected_date:
            current_streak += 1
        else:
            break
    return current_streak

def process_to_json(df):
    df['date_dt'] = pd.to_datetime(df['date'])
    df['day_str'] = df['date_dt'].dt.date
    df['hour'] = df['date_dt'].dt.hour
    df['weekday'] = df['date_dt'].dt.weekday # 0=Mon, 6=Sun
    
    # 1. åŸºç¡€ç»Ÿè®¡
    total_commits = len(df)
    last_update = df['date_dt'].max().strftime("%Y-%m-%d %H:%M")
    unique_days = df['day_str'].unique().tolist()
    current_streak = calculate_streak(unique_days)
    
    # 2. è¶‹åŠ¿å›¾ (æŒ‰å¤©)
    daily_counts = df.groupby('day_str').size().reset_index(name='count')
    daily_counts = daily_counts.sort_values('day_str')
    
    # 3. æ´»è·ƒæ—¶é—´åˆ†å¸ƒ (å‘¨ x å°æ—¶) - ç”¨äºçƒ­åŠ›å›¾
    heatmap_data = []
    grouped = df.groupby(['weekday', 'hour']).size().reset_index(name='count')
    for _, row in grouped.iterrows():
        # ECharts heatmap æ ¼å¼: [x, y, value] -> [hour, weekday, count]
        heatmap_data.append([int(row['hour']), int(row['weekday']), int(row['count'])])

    # 4. æœ€è¿‘æäº¤è®°å½• (å–å‰ 10 æ¡)
    recent_commits = df.head(10)[['hash', 'message', 'date']].astype(str).to_dict(orient='records')

    data = {
        "meta": {
            "repo": REPO_URL.split('/')[-1],
            "updated": last_update,
            "total": total_commits,
            "streak": current_streak
        },
        "trend": {
            "dates": daily_counts['day_str'].astype(str).tolist(),
            "values": daily_counts['count'].tolist()
        },
        "heatmap": heatmap_data,
        "recent": recent_commits
    }
    return data

def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    if os.path.exists(TEMPLATE_FILE):
        shutil.copy(TEMPLATE_FILE, os.path.join(OUTPUT_DIR, "index.html"))
    
    df = fetch_commit_data(REPO_URL)
    if df is not None and not df.empty:
        json_data = process_to_json(df)
        with open(JSON_FILE, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False)
        print(f"ğŸ‰ æ•°æ®å·²ç”Ÿæˆ: {JSON_FILE}")
    else:
        print("âŒ æ— æ•°æ®")

if __name__ == "__main__":
    main()
